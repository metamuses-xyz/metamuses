version: '3.8'

# ============================================================================
# MetaMuses API - Production Docker Compose
# https://api.metamuses.xyz
#
# Multi-Worker Configuration for 16 CPU / 32GB RAM (Hetzner ARM64)
# Default: 4 workers with 4 threads each = 16 CPUs utilized
#
# Services:
#   - postgres    : PostgreSQL 16 database
#   - redis       : Redis 7 queue manager
#   - qdrant      : Vector database for semantic caching
#   - api         : MetaMuses API server
#   - worker-0/1/2/3 : Background AI inference workers (scalable)
#   - prometheus  : Metrics collection
#   - grafana     : Monitoring dashboard
# ============================================================================

# Worker configuration (set these in .env)
# TOTAL_WORKERS=4          # Number of worker containers
# THREADS_PER_WORKER=4     # CPU threads per worker (16 / 4 = 4)
# BATCH_SIZE=512           # Batch size for prompt processing
# CONTEXT_SIZE=2048        # Context window size

x-worker-common: &worker-common
  build:
    context: ../..
    dockerfile: deployment/docker/Dockerfile
    target: worker
  restart: unless-stopped
  depends_on:
    redis:
      condition: service_healthy
  volumes:
    - /mnt/models:/models:ro
    - worker_logs:/app/logs
  networks:
    - metamuses-network
  environment: &worker-env
    # Redis
    - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme}@redis:6379
    - REDIS_QUEUE_PREFIX=metamuse

    # Models
    - MODELS_DIR=/models
    - ENABLE_FAST_TIER=${ENABLE_FAST_TIER:-true}
    - ENABLE_MEDIUM_TIER=${ENABLE_MEDIUM_TIER:-false}
    - ENABLE_HEAVY_TIER=${ENABLE_HEAVY_TIER:-false}

    # Worker Configuration (shared)
    - TOTAL_WORKERS=${TOTAL_WORKERS:-4}
    - THREADS_PER_WORKER=${THREADS_PER_WORKER:-4}
    - BATCH_SIZE=${BATCH_SIZE:-512}
    - CONTEXT_SIZE=${CONTEXT_SIZE:-2048}
    - MAX_TOKENS=${MAX_TOKENS:-32}

    # Semantic Cache (disabled by default for performance)
    - ENABLE_SEMANTIC_CACHE=${ENABLE_SEMANTIC_CACHE:-false}

    # Logging
    - RUST_LOG=${RUST_LOG:-info}
    - RUST_BACKTRACE=${RUST_BACKTRACE:-1}
  logging:
    driver: "json-file"
    options:
      max-size: "50m"
      max-file: "5"
  deploy:
    resources:
      limits:
        cpus: '${THREADS_PER_WORKER:-4}'
        memory: ${WORKER_MEMORY_LIMIT:-6G}
      reservations:
        cpus: '${THREADS_PER_WORKER:-4}'
        memory: ${WORKER_MEMORY_RESERVATION:-4G}

services:
  # ==========================================================================
  # PostgreSQL - Primary Database
  # ==========================================================================
  postgres:
    image: postgres:16-alpine
    container_name: metamuses-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-metamuse}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-changeme}
      - POSTGRES_DB=${POSTGRES_DB:-metamuses}
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "127.0.0.1:5432:5432"
    networks:
      - metamuses-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-metamuse} -d ${POSTGRES_DB:-metamuses}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ==========================================================================
  # Redis - Queue Manager
  # ==========================================================================
  redis:
    image: redis:7-alpine
    container_name: metamuses-redis
    restart: unless-stopped
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
      --requirepass ${REDIS_PASSWORD:-changeme}
    volumes:
      - redis_data:/data
    ports:
      - "127.0.0.1:6379:6379"
    networks:
      - metamuses-network
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-changeme}", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 5s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # ==========================================================================
  # Qdrant - Vector Database for Semantic Caching (Optional)
  # ==========================================================================
  qdrant:
    image: qdrant/qdrant:latest
    container_name: metamuses-qdrant
    restart: unless-stopped
    profiles:
      - semantic-cache  # Only start when semantic cache is enabled
    volumes:
      - qdrant_storage:/qdrant/storage
    ports:
      - "127.0.0.1:6333:6333"
      - "127.0.0.1:6334:6334"
    networks:
      - metamuses-network
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__STORAGE__STORAGE_PATH=/qdrant/storage
      - QDRANT__LOG_LEVEL=INFO
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:6333/healthz || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # ==========================================================================
  # MetaMuses API - Main Application Server
  # ==========================================================================
  api:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile
      target: server
    image: metamuses-api:latest
    container_name: metamuses-api
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - /mnt/models:/models:ro
      - api_logs:/app/logs
    ports:
      - "127.0.0.1:8080:8080"
    networks:
      - metamuses-network
    environment:
      # Server
      - HOST=0.0.0.0
      - PORT=8080

      # Database
      - DATABASE_URL=postgres://${POSTGRES_USER:-metamuse}:${POSTGRES_PASSWORD:-changeme}@postgres:5432/${POSTGRES_DB:-metamuses}

      # Redis
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme}@redis:6379
      - REDIS_QUEUE_PREFIX=metamuse

      # Qdrant (optional)
      - QDRANT_URL=http://qdrant:6334
      - QDRANT_API_KEY=${QDRANT_API_KEY:-}

      # Models
      - MODELS_DIR=/models
      - ENABLE_FAST_TIER=${ENABLE_FAST_TIER:-true}
      - ENABLE_MEDIUM_TIER=${ENABLE_MEDIUM_TIER:-false}
      - ENABLE_HEAVY_TIER=${ENABLE_HEAVY_TIER:-false}

      # Worker Pools (for in-process workers - not used with separate containers)
      - FAST_TIER_WORKERS=0
      - MEDIUM_TIER_WORKERS=0
      - HEAVY_TIER_WORKERS=0

      # Semantic Cache (disabled by default)
      - ENABLE_SEMANTIC_CACHE=${ENABLE_SEMANTIC_CACHE:-false}
      - CACHE_SIMILARITY_THRESHOLD=${CACHE_SIMILARITY_THRESHOLD:-0.95}
      - CACHE_TTL_HOURS=${CACHE_TTL_HOURS:-24}

      # Blockchain
      - RPC_URL=${RPC_URL}
      - PRIVATE_KEY=${PRIVATE_KEY}
      - IPFS_JWT_TOKEN=${IPFS_JWT_TOKEN}
      - CONTRACT_ADDRESS=${CONTRACT_ADDRESS:-0xE7612c29d2e73db07c7a4245741b38D2beB36308}

      # Logging
      - RUST_LOG=${RUST_LOG:-info}
      - RUST_BACKTRACE=${RUST_BACKTRACE:-1}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "5"
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G

  # ==========================================================================
  # MetaMuses Workers - Background AI Inference Workers (4 instances)
  # Each worker gets THREADS_PER_WORKER CPU threads
  # ==========================================================================

  worker-0:
    <<: *worker-common
    container_name: metamuses-worker-0
    image: metamuses-worker:latest
    environment:
      - WORKER_ID=0
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme}@redis:6379
      - REDIS_QUEUE_PREFIX=metamuse
      - MODELS_DIR=/models
      - ENABLE_FAST_TIER=${ENABLE_FAST_TIER:-true}
      - ENABLE_MEDIUM_TIER=${ENABLE_MEDIUM_TIER:-false}
      - ENABLE_HEAVY_TIER=${ENABLE_HEAVY_TIER:-false}
      - TOTAL_WORKERS=${TOTAL_WORKERS:-4}
      - THREADS_PER_WORKER=${THREADS_PER_WORKER:-4}
      - BATCH_SIZE=${BATCH_SIZE:-512}
      - CONTEXT_SIZE=${CONTEXT_SIZE:-2048}
      - ENABLE_SEMANTIC_CACHE=${ENABLE_SEMANTIC_CACHE:-false}
      - RUST_LOG=${RUST_LOG:-info}
      - RUST_BACKTRACE=${RUST_BACKTRACE:-1}

  worker-1:
    <<: *worker-common
    container_name: metamuses-worker-1
    image: metamuses-worker:latest
    environment:
      - WORKER_ID=1
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme}@redis:6379
      - REDIS_QUEUE_PREFIX=metamuse
      - MODELS_DIR=/models
      - ENABLE_FAST_TIER=${ENABLE_FAST_TIER:-true}
      - ENABLE_MEDIUM_TIER=${ENABLE_MEDIUM_TIER:-false}
      - ENABLE_HEAVY_TIER=${ENABLE_HEAVY_TIER:-false}
      - TOTAL_WORKERS=${TOTAL_WORKERS:-4}
      - THREADS_PER_WORKER=${THREADS_PER_WORKER:-4}
      - BATCH_SIZE=${BATCH_SIZE:-512}
      - CONTEXT_SIZE=${CONTEXT_SIZE:-2048}
      - ENABLE_SEMANTIC_CACHE=${ENABLE_SEMANTIC_CACHE:-false}
      - RUST_LOG=${RUST_LOG:-info}
      - RUST_BACKTRACE=${RUST_BACKTRACE:-1}
    profiles:
      - multi-worker

  worker-2:
    <<: *worker-common
    container_name: metamuses-worker-2
    image: metamuses-worker:latest
    environment:
      - WORKER_ID=2
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme}@redis:6379
      - REDIS_QUEUE_PREFIX=metamuse
      - MODELS_DIR=/models
      - ENABLE_FAST_TIER=${ENABLE_FAST_TIER:-true}
      - ENABLE_MEDIUM_TIER=${ENABLE_MEDIUM_TIER:-false}
      - ENABLE_HEAVY_TIER=${ENABLE_HEAVY_TIER:-false}
      - TOTAL_WORKERS=${TOTAL_WORKERS:-4}
      - THREADS_PER_WORKER=${THREADS_PER_WORKER:-4}
      - BATCH_SIZE=${BATCH_SIZE:-512}
      - CONTEXT_SIZE=${CONTEXT_SIZE:-2048}
      - ENABLE_SEMANTIC_CACHE=${ENABLE_SEMANTIC_CACHE:-false}
      - RUST_LOG=${RUST_LOG:-info}
      - RUST_BACKTRACE=${RUST_BACKTRACE:-1}
    profiles:
      - multi-worker

  worker-3:
    <<: *worker-common
    container_name: metamuses-worker-3
    image: metamuses-worker:latest
    environment:
      - WORKER_ID=3
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme}@redis:6379
      - REDIS_QUEUE_PREFIX=metamuse
      - MODELS_DIR=/models
      - ENABLE_FAST_TIER=${ENABLE_FAST_TIER:-true}
      - ENABLE_MEDIUM_TIER=${ENABLE_MEDIUM_TIER:-false}
      - ENABLE_HEAVY_TIER=${ENABLE_HEAVY_TIER:-false}
      - TOTAL_WORKERS=${TOTAL_WORKERS:-4}
      - THREADS_PER_WORKER=${THREADS_PER_WORKER:-4}
      - BATCH_SIZE=${BATCH_SIZE:-512}
      - CONTEXT_SIZE=${CONTEXT_SIZE:-2048}
      - ENABLE_SEMANTIC_CACHE=${ENABLE_SEMANTIC_CACHE:-false}
      - RUST_LOG=${RUST_LOG:-info}
      - RUST_BACKTRACE=${RUST_BACKTRACE:-1}
    profiles:
      - multi-worker

  # ==========================================================================
  # Prometheus - Metrics Collection
  # ==========================================================================
  prometheus:
    image: prom/prometheus:latest
    container_name: metamuses-prometheus
    restart: unless-stopped
    profiles:
      - monitoring
    user: "65534:65534"
    volumes:
      - ../monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "127.0.0.1:9090:9090"
    networks:
      - metamuses-network
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # ==========================================================================
  # Grafana - Monitoring Dashboard
  # ==========================================================================
  grafana:
    image: grafana/grafana:latest
    container_name: metamuses-grafana
    restart: unless-stopped
    profiles:
      - monitoring
    depends_on:
      - prometheus
    user: "472:472"
    volumes:
      - grafana_data:/var/lib/grafana
      - ../monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ../monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    ports:
      - "127.0.0.1:3000:3000"
    networks:
      - metamuses-network
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-changeme}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=https://api.metamuses.xyz/grafana
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
      - GF_INSTALL_PLUGINS=
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M

# ============================================================================
# Networks
# ============================================================================
networks:
  metamuses-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# ============================================================================
# Volumes
# ============================================================================
volumes:
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /mnt/data/postgres

  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /mnt/data/redis

  qdrant_storage:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /mnt/data/qdrant

  prometheus_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /mnt/data/prometheus

  grafana_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /mnt/data/grafana

  api_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/metamuses/logs/api

  worker_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /opt/metamuses/logs/worker
